{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f04fb501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "deb7928a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('../names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c71f54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6a36b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq=list(set(c for w in words for c in w))\n",
    "uniq= uniq + ['.']\n",
    "vocab=sorted(uniq)\n",
    "stoi = {c:i for i,c in enumerate(vocab) }\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6e0034e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len=len(vocab)\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "99edbb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... --> e\n",
      "..e --> m\n",
      ".em --> m\n",
      "emm --> a\n",
      "mma --> .\n",
      "... --> o\n",
      "..o --> l\n",
      ".ol --> i\n",
      "oli --> v\n",
      "liv --> i\n",
      "ivi --> a\n",
      "via --> .\n",
      "... --> a\n",
      "..a --> v\n",
      ".av --> a\n",
      "ava --> .\n",
      "... --> i\n",
      "..i --> s\n",
      ".is --> a\n",
      "isa --> b\n",
      "sab --> e\n",
      "abe --> l\n",
      "bel --> l\n",
      "ell --> a\n",
      "lla --> .\n",
      "... --> s\n",
      "..s --> o\n",
      ".so --> p\n",
      "sop --> h\n",
      "oph --> i\n",
      "phi --> a\n",
      "hia --> .\n"
     ]
    }
   ],
   "source": [
    "block_size=3\n",
    "X,Y=[],[]\n",
    "for w in words[:5]:\n",
    "  context = [0]*block_size\n",
    "  for ch in w+'.':\n",
    "    X.append(context)\n",
    "    Y.append(stoi[ch])\n",
    "    print(f'{\"\".join(itos[c] for c in context)} --> {ch}')\n",
    "    context = context[1:] + [stoi[ch]]\n",
    "\n",
    "X=torch.tensor(X)\n",
    "Y=torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b7c2fb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "520c369f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_emb=2\n",
    "C=torch.randn((vocab_len, 2))\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ee1aaa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.1406,  0.5764],\n",
       "         [-0.1223,  0.8116],\n",
       "         [-0.1223,  0.8116]]),\n",
       " tensor([ 5, 13, 13]),\n",
       " tensor([[-2.1406,  0.5764],\n",
       "         [-0.1223,  0.8116],\n",
       "         [-0.1223,  0.8116]]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb=C[X]\n",
    "print(emb.shape)\n",
    "\n",
    "emb[3], X[3], C[[5,13,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b6fa80fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), torch.Size([100]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neurons=100\n",
    "W1 = torch.randn((block_size*n_emb, n_neurons))\n",
    "b1 = torch.randn(n_neurons)\n",
    "W1.shape, b1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "035ac91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 27]), torch.Size([27]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = torch.randn((n_neurons, vocab_len))\n",
    "b2 = torch.randn(vocab_len)\n",
    "W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "988c7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preact = emb.view(-1, block_size*n_emb) @ W1 + b1\n",
    "h = torch.tanh(preact)\n",
    "logits = h @ W2 + b2\n",
    "probs =  F.softmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1bb30fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.5960)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e115d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train prep\n",
    "n_emb=2\n",
    "n_neurons=100\n",
    "block_size=3\n",
    "\n",
    "X,Y=[],[]\n",
    "for w in words:\n",
    "  context = [0]*block_size\n",
    "  for ch in w+'.':\n",
    "    X.append(context)\n",
    "    Y.append(stoi[ch])\n",
    "    #print(f'{\"\".join(itos[c] for c in context)} --> {ch}')\n",
    "    context = context[1:] + [stoi[ch]]\n",
    "\n",
    "X=torch.tensor(X)\n",
    "Y=torch.tensor(Y)\n",
    "\n",
    "# init\n",
    "C  = torch.randn((vocab_len, n_emb))\n",
    "W1 = torch.randn((block_size*n_emb, n_neurons))\n",
    "b1 = torch.randn(n_neurons)\n",
    "W2 = torch.randn((n_neurons, vocab_len))\n",
    "b2 = torch.randn(vocab_len)\n",
    "\n",
    "parameters = [C,W1,b1,W2,b2]\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1c2e3f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ada5e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5242, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "lr = 0.01\n",
    "\n",
    "for _ in range(10_000):\n",
    "  # minibatch\n",
    "  batch = torch.randint(0, X.shape[0], (64,))\n",
    "\n",
    "  # forward pass\n",
    "  emb=C[X[batch]]\n",
    "  preact = emb.view(-1, block_size*n_emb) @ W1 + b1\n",
    "  h = torch.tanh(preact)\n",
    "  logits = h @ W2 + b2\n",
    "  loss = F.cross_entropy(logits, Y[batch])\n",
    "  \n",
    "  # clear grads\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  # recompute grads\n",
    "  loss.backward()\n",
    "  # update\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b8fd7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "liffihade.\n",
      "mhienara.\n",
      "ahi.\n",
      "aorilen.\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "out=[]\n",
    "for i in range(5):\n",
    "  out.append([])\n",
    "  context = [0] * block_size\n",
    "  while True:\n",
    "    # forward pass\n",
    "    emb = C[context]\n",
    "    preact = emb.view(-1, block_size*n_emb) @ W1 + b1\n",
    "    h = torch.tanh(preact)\n",
    "    logits = h @ W2 + b2\n",
    "    probs = F.softmax(logits, 1)\n",
    "    hit = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "    out[i].append(hit)\n",
    "    if hit == 0:\n",
    "      break\n",
    "    context = context[1:] + [hit]\n",
    "for o in out:\n",
    "  print(''.join(itos[x] for x in o))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymakemore (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

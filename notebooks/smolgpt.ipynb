{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5118beb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_text = open('../data/tinyshakespeare.txt', 'r').read()\n",
    "lines = whole_text.splitlines()\n",
    "len(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "58a33b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(''.join(whole_text)))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, ''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ea85b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "stoi = {c:i for i,c in enumerate(vocab)}\n",
    "itos = {v:k for k,v in stoi.items()}\n",
    "encode = lambda str: [stoi[c] for c in str]\n",
    "decode = lambda ints: ''.join([itos[i] for i in ints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cd16f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6d516e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115394]), torch.int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(whole_text))\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1dd88c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1003854]), torch.Size([111540]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(data.shape[0] * .9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "79b7021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "72596891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) -> 47\n",
      "tensor([18, 47]) -> 56\n",
      "tensor([18, 47, 56]) -> 57\n",
      "tensor([18, 47, 56, 57]) -> 58\n",
      "tensor([18, 47, 56, 57, 58]) -> 1\n",
      "tensor([18, 47, 56, 57, 58,  1]) -> 15\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) -> 47\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n"
     ]
    }
   ],
   "source": [
    "# time (T) apparently (or T as in Token?)\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(len(x),):\n",
    "  context = x[:t+1]\n",
    "  print(f'{context} -> {y[t]}')\n",
    "\n",
    "# this is apparently called T (time) dimension? or Token? \n",
    "# i think from the BTC acronym we'll see more of later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "12ab60e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "         [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "         [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "         [25, 17, 27, 10,  0, 21,  1, 54]]),\n",
       " torch.Size([4, 8]),\n",
       " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "         [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "         [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "         [17, 27, 10,  0, 21,  1, 54, 39]]),\n",
       " torch.Size([4, 8]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "# batch (B)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  # get offset starts for all batches\n",
    "  ix = torch.randint(0, data.shape[0]-block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "  return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "xb,xb.shape, yb, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "230aab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n",
      "torch.Size([])\n",
      "\n",
      "eefnrXLFs?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "n_embd = 32\n",
    "\n",
    "class Head(nn.Module):\n",
    "  def __init__(self, head_size):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "  def forward(self, x):\n",
    "    B,T,C = x.shape\n",
    "    k = self.key(x)\n",
    "    q = self.query(x) # (B,T,C)\n",
    "    # note: not sure which this square root came from hmmm\n",
    "    wei = k @ q.transpose(-2,-1) * C**-0.5 \n",
    "    # decoder\n",
    "    # note: review this indexing again [:T,:T]\n",
    "    wei = wei.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n",
    "    wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "    v = self.value(x) \n",
    "    out = wei @ v\n",
    "    return out\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super().__init__()\n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "    self.sa_head = Head(n_embd)\n",
    "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "  \n",
    "  def forward(self, idx, targets=None):\n",
    "    B,T = idx.shape\n",
    "    # idx = (B,T) \n",
    "    tok_emb = self.token_embedding_table(idx) # -> (B, T, n_embd)\n",
    "    pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "    x = tok_emb + pos_emb\n",
    "    x = self.sa_head(x)\n",
    "    logits = self.lm_head(x) # -> (B, T, vocab_size)\n",
    "\n",
    "    if targets is None:\n",
    "      return logits, None\n",
    "\n",
    "    B,T,C = logits.shape\n",
    "    targets = targets.view(B*T)\n",
    "    loss = F.cross_entropy(logits.view(B*T,C), targets)\n",
    "    return logits, loss\n",
    "  \n",
    "  def generate(self, idx, max_tokens=10):\n",
    "    for _ in range(max_tokens):\n",
    "      idx_inrange = idx[:,-block_size:]\n",
    "      logits, loss = self(idx_inrange)\n",
    "      # take the last T as this contains the predictions for next char\n",
    "      logits = logits[:, -1, :] # (B,T,C) -> (B,C)\n",
    "      probs = F.softmax(logits, dim=-1)\n",
    "      hit = torch.multinomial(probs, num_samples=1) # note: this fn returns indices\n",
    "      idx = torch.cat((idx, hit), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "m = Bigram()\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss.shape)\n",
    "\n",
    "infe = m.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=10)[0]\n",
    "print(decode(infe.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e9ca94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5800b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3524, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "for _ in range(10_000):\n",
    "  xb,yb = get_batch(\"train\")\n",
    "  logits,loss = m(xb,yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "36f0351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sayine yo, lod weangju not bouth lappono id lthathere lot lrt marar dedad myowr, adt mine is, tofre\n",
      "I hel,\n",
      "WAROMy omey ngollou tand:\n",
      "Iserord oche ty fas fame cisprue:\n",
      "Hot as thath goutheandd dist ye fatr I shary neif nance hadis ogoenewnge h'doudsorno me lyoowe branllerlat lyof mal Willld, our n thoror is hat sen Jeme, Meccitel YI fornds.\n",
      "\n",
      "LOLA:\n",
      "Mome.\n",
      "\n",
      "There sor far by toruch, can eangerre, ay, ho\n"
     ]
    }
   ],
   "source": [
    "infe = m.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=400)[0]\n",
    "print(decode(infe.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymakemore (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

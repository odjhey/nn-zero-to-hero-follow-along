{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5118beb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_text = open('../data/tinyshakespeare.txt', 'r').read()\n",
    "lines = whole_text.splitlines()\n",
    "len(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "58a33b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(''.join(whole_text)))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, ''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ea85b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "stoi = {c:i for i,c in enumerate(vocab)}\n",
    "itos = {v:k for k,v in stoi.items()}\n",
    "encode = lambda str: [stoi[c] for c in str]\n",
    "decode = lambda ints: ''.join([itos[i] for i in ints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cd16f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6d516e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115394]), torch.int64)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(whole_text))\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1dd88c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1003854]), torch.Size([111540]))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(data.shape[0] * .9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "79b7021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "72596891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) -> 47\n",
      "tensor([18, 47]) -> 56\n",
      "tensor([18, 47, 56]) -> 57\n",
      "tensor([18, 47, 56, 57]) -> 58\n",
      "tensor([18, 47, 56, 57, 58]) -> 1\n",
      "tensor([18, 47, 56, 57, 58,  1]) -> 15\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) -> 47\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n"
     ]
    }
   ],
   "source": [
    "# time (T) apparently (or T as in Token?)\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(len(x),):\n",
    "  context = x[:t+1]\n",
    "  print(f'{context} -> {y[t]}')\n",
    "\n",
    "# this is apparently called T (time) dimension? or Token? \n",
    "# i think from the BTC acronym we'll see more of later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "12ab60e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "         [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "         [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "         [25, 17, 27, 10,  0, 21,  1, 54]]),\n",
       " torch.Size([4, 8]),\n",
       " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "         [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "         [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "         [17, 27, 10,  0, 21,  1, 54, 39]]),\n",
       " torch.Size([4, 8]))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "# batch (B)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  # get offset starts for all batches\n",
    "  ix = torch.randint(0, data.shape[0]-block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "  return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "xb,xb.shape, yb, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "230aab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n",
      "torch.Size([])\n",
      "\n",
      "cZCm\n",
      "$-ixX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "n_embd = 32\n",
    "\n",
    "class Head(nn.Module):\n",
    "  def __init__(self, head_size):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "  def forward(self, x):\n",
    "    B,T,C = x.shape\n",
    "    k = self.key(x)\n",
    "    q = self.query(x) # (B,T,C)\n",
    "    # note: not sure which this square root came from hmmm, we may need to recheck the paper\n",
    "    wei = k @ q.transpose(-2,-1) * C**-0.5 \n",
    "    # decoder\n",
    "    # note: review this indexing again [:T,:T]\n",
    "    wei = wei.masked_fill(self.tril[:T,:T]==0, float('-inf'))\n",
    "    wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "    v = self.value(x) \n",
    "    out = wei @ v\n",
    "    return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, num_heads, head_size):\n",
    "    super().__init__()\n",
    "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, n_embd):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "      nn.Linear(n_embd, n_embd),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "  def forward(self,x):\n",
    "    return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self, n_embd, n_head):\n",
    "    super().__init__()\n",
    "    head_size = n_embd // n_head\n",
    "    self.sa = MultiHeadAttention(n_head, head_size)\n",
    "    self.ffwd = FeedForward(n_embd)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.sa(x)\n",
    "    x = self.ffwd(x)\n",
    "    return x\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super().__init__()\n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "    self.blocks = nn.Sequential(\n",
    "      Block(n_embd, n_head=4),\n",
    "      Block(n_embd, n_head=4),\n",
    "      Block(n_embd, n_head=4),\n",
    "    )\n",
    "\n",
    "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "  \n",
    "  def forward(self, idx, targets=None):\n",
    "    B,T = idx.shape\n",
    "    # idx = (B,T) \n",
    "    tok_emb = self.token_embedding_table(idx) # -> (B, T, n_embd)\n",
    "    pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "    x = tok_emb + pos_emb\n",
    "    x = self.blocks(x)\n",
    "    logits = self.lm_head(x) # -> (B, T, vocab_size)\n",
    "\n",
    "    if targets is None:\n",
    "      return logits, None\n",
    "\n",
    "    B,T,C = logits.shape\n",
    "    targets = targets.view(B*T)\n",
    "    loss = F.cross_entropy(logits.view(B*T,C), targets)\n",
    "    return logits, loss\n",
    "  \n",
    "  def generate(self, idx, max_tokens=10):\n",
    "    for _ in range(max_tokens):\n",
    "      idx_inrange = idx[:,-block_size:]\n",
    "      logits, loss = self(idx_inrange)\n",
    "      # take the last T as this contains the predictions for next char\n",
    "      logits = logits[:, -1, :] # (B,T,C) -> (B,C)\n",
    "      probs = F.softmax(logits, dim=-1)\n",
    "      hit = torch.multinomial(probs, num_samples=1) # note: this fn returns indices\n",
    "      idx = torch.cat((idx, hit), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "m = Bigram()\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss.shape)\n",
    "\n",
    "infe = m.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=10)[0]\n",
    "print(decode(infe.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2e9ca94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cb5800b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1400, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "for _ in range(10_000):\n",
    "  xb,yb = get_batch(\"train\")\n",
    "  logits,loss = m(xb,yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "df2ecf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.140007734298706\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "36f0351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "So tarl.\n",
      "\n",
      "KLES:\n",
      "Lore the bowen not flou\n",
      "Wstoo.\n",
      "JESSBY:\n",
      "Hill saslad?\n",
      "\n",
      "De\n",
      "Thigh you your onel swale.\n",
      "\n",
      "VDNUDENT:\n",
      "Lousre lit to of heusovend reallieslow'r put his asted.\n",
      "Shert my bosed, his be-uney.\n",
      "\n",
      "CLKENEA:\n",
      "Whoou.\n",
      "\n",
      "CARDY I FIO:\n",
      "Yaou wour.\n",
      "\n",
      "LICCUBKT:\n",
      "Ik snarrthou wasf.\n",
      "Thit I sheiss!\n",
      "Forly,\n",
      "Thome oettnof agar soed youor may on sowat,\n",
      "Bolle that tow necy-soo hy the briem?\n",
      "\n",
      "LIXNILO:\n",
      "Thodo;\n",
      "Nother telwerted'\n",
      "nou, on nold his hesveare thit of the o'ncled\n",
      "tracthine on to have,\n",
      "Bofors:\n",
      "Rye go to ade\n",
      "Sell, of\n",
      "droodg will seertoo.\n",
      "\n",
      "DUQULI:\n",
      "Maerl tingip the oman'd omou an Bwror your. KLow agtoo Jgo I be to fishen,\n",
      "Mold to must mangas whar to lomode ow was wour herver\n",
      "Whe lard of by hemveny thich\n",
      "Thint he heat hery.\n",
      "Yodoth te so thas,\n",
      "Ond, gond me doo diord-Ctreari you lavede, and a bry hanctuld fe arne tars rof hed anddanl;\n",
      "NUmune to sext RI your fell asher comtar' meray. I crour darot ingadem a knobl weunged,\n",
      "And nor my lot ind Stich ske doten, me my nour, shisild in fe, asecrell heray,\n",
      "Mut dratilpim acke hemestpilodse\n"
     ]
    }
   ],
   "source": [
    "infe = m.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=1023)[0]\n",
    "print(decode(infe.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymakemore (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5118beb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_text = open('../data/tinyshakespeare.txt', 'r').read()\n",
    "lines = whole_text.splitlines()\n",
    "len(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "58a33b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, \"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(''.join(whole_text)))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, ''.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea85b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "stoi = {c:i for i,c in enumerate(vocab)}\n",
    "itos = {v:k for k,v in stoi.items()}\n",
    "encode = lambda str: [stoi[c] for c in str]\n",
    "decode = lambda ints: ''.join([itos[i] for i in ints])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cd16f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6d516e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115394]), torch.int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(whole_text))\n",
    "data.shape, data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1dd88c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1003854]), torch.Size([111540]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(data.shape[0] * .9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "79b7021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "72596891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18]) -> 47\n",
      "tensor([18, 47]) -> 56\n",
      "tensor([18, 47, 56]) -> 57\n",
      "tensor([18, 47, 56, 57]) -> 58\n",
      "tensor([18, 47, 56, 57, 58]) -> 1\n",
      "tensor([18, 47, 56, 57, 58,  1]) -> 15\n",
      "tensor([18, 47, 56, 57, 58,  1, 15]) -> 47\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n"
     ]
    }
   ],
   "source": [
    "# time (T) apparently (or T as in Token?)\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(len(x),):\n",
    "  context = x[:t+1]\n",
    "  print(f'{context} -> {y[t]}')\n",
    "\n",
    "# this is apparently called T (time) dimension? or Token? \n",
    "# i think from the BTC acronym we'll see more of later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "12ab60e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "         [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "         [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "         [25, 17, 27, 10,  0, 21,  1, 54]]),\n",
       " torch.Size([4, 8]),\n",
       " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "         [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "         [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "         [17, 27, 10,  0, 21,  1, 54, 39]]),\n",
       " torch.Size([4, 8]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "# batch (B)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  # get offset starts for all batches\n",
    "  ix = torch.randint(0, data.shape[0]-block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "  return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "xb,xb.shape, yb, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "230aab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 65])\n",
      "torch.Size([])\n",
      "\n",
      "SmVddomOVW\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "n_embd = 32\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "  def __init__(self,):\n",
    "    super().__init__()\n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "  \n",
    "  def forward(self, idx, targets=None):\n",
    "    B,T = idx.shape\n",
    "    # idx = (B,T) \n",
    "    tok_emb = self.token_embedding_table(idx) # -> (B, T, n_embd)\n",
    "    pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "    x = tok_emb + pos_emb\n",
    "    logits = self.lm_head(x) # -> (B, T, vocab_size)\n",
    "\n",
    "    if targets is None:\n",
    "      return logits, None\n",
    "\n",
    "    B,T,C = logits.shape\n",
    "    targets = targets.view(B*T)\n",
    "    loss = F.cross_entropy(logits.view(B*T,C), targets)\n",
    "    return logits, loss\n",
    "  \n",
    "  def generate(self, idx, max_tokens=10):\n",
    "    for _ in range(max_tokens):\n",
    "      idx_inrange = idx[:,-block_size:]\n",
    "      logits, loss = self(idx_inrange)\n",
    "      # take the last T as this contains the predictions for next char\n",
    "      logits = logits[:, -1, :] # (B,T,C) -> (B,C)\n",
    "      probs = F.softmax(logits, dim=-1)\n",
    "      hit = torch.multinomial(probs, num_samples=1) # note: this fn returns indices\n",
    "      idx = torch.cat((idx, hit), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "m = Bigram()\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss.shape)\n",
    "\n",
    "infe = m.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=10)[0]\n",
    "print(decode(infe.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2e9ca94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb5800b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3978, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "for _ in range(10_000):\n",
    "  xb,yb = get_batch(\"train\")\n",
    "  logits,loss = m(xb,yb)\n",
    "  optimizer.zero_grad(set_to_none=True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "36f0351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LESiekiby\n",
      "Tiry bakire med anon:\n",
      "O, ot my y'ld bello pond,\n",
      "net ysoreliule.\n",
      "INGl,\n",
      "CENToungrrdonil k Bur s th pow ced wilouse, ase ic parl gum haagr t w fune hen seringou INVat? US:\n",
      "Wo bof,\n",
      "Whind t mye threntcooshe, whiks wad ppal'lsp\n",
      "Thad! sat!\n",
      "Yod t ou thipleain tu t an s phue s mangreste t, ce, m wane ssichalispres lldofr, ther ionomay:\n",
      "ALOMo? IEETIINO:\n",
      "WA we kiemans o wlake, be!\n",
      "Wh y tispeina'd?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infe = m.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=400)[0]\n",
    "print(decode(infe.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mymakemore (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
